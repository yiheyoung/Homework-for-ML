# -*- coding: utf-8 -*-
"""
Created on Thu Jan 30 17:13:29 2020

@author: ysxh1998
"""
import tensorflow as tf
import numpy as np
from keras.layers import SimpleRNN
from keras.models import Sequential
from keras.layers import Embedding
from keras.preprocessing import sequence
from keras.layers import LSTM
from keras.layers import Dense
from tensorflow.keras import layers


r = np.load('E:/python/RNN/data_arr_150.npy')
#print(r[2])
for subject in r:
    col_mean = np.nanmean(subject,axis=0)
    nan_ind = np.where(np.isnan(col_mean))
    col_mean[nan_ind] = 0
    #print(col_mean)
    inds = np.where(np.isnan(subject))
    #print(inds)
    #print(subject[inds])
    subject[inds] = np.take(col_mean,inds[1])
    #print(inds[1])

m = np.load('E:/python/RNN/labels_150.npy')
#list = []
#i = 0
for subject in m:
    mean = np.nanmean(subject)
    if mean > 0:
        inds = np.where(np.isnan(subject))
        subject[inds] = 1
    else:
        inds_1 = np.where(np.isnan(subject))
        subject[inds_1] = 0
        #list.append(i)
    #i = i+1
#print(list)
#print(np.asarray(list).shape)
#print(r[1])
#r = np.reshape(r,(20179,6040))
#print(r[1])
print(r.shape)
#print(m[6])
#print(m[58])
#print(m[62])
#print(m[71])
#print(m[78])

max_features = 6040  # number of words to consider as features
maxlen = 40  # cut texts after this number of words (among top max_features most common words)

input_train = r[0:20000]
y_train = m[0:20000]
input_test = r[20000:]
y_test = m[20000:]

#input_train = sequence.pad_sequences(input_train, maxlen=maxlen)
#input_test = sequence.pad_sequences(input_test, maxlen=maxlen)

y_train = np.reshape(y_train,(20000,151,1))

model = Sequential()

model.add(LSTM(100, return_sequences=True, input_shape=(151, 40)))

# The output of GRU will be a 3D tensor of shape (batch_size, timesteps, 256)

# The output of SimpleRNN will be a 2D tensor of shape (batch_size, 128)


model.add(Dense(1, activation='sigmoid'))
model.summary()


model.compile(optimizer='rmsprop',
              loss='binary_crossentropy',
              metrics=['acc'])
history = model.fit(input_train, y_train,
                    epochs=10,
                    batch_size=40,
                    validation_split=0.2)























